{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📘 Informe de solución\n",
    "**Proyecto:** Predicción de Churn en Clientes de Telecomunicaciones  \n",
    "**Autor:** Aurelio  \n",
    "**Fecha:** Septiembre 2025\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Análisis preliminar\n",
    "\n",
    "Se inició el proyecto con la exploración de los archivos `contract.csv`, `personal.csv`, `phone.csv` e `internet.csv`. Se detectaron diferencias en la cantidad de registros, lo que llevó a establecer `customerID` como clave principal para la integración.\n",
    "\n",
    "La variable objetivo `Churn` no estaba explícita, pero se derivó correctamente a partir de la columna `EndDate`. También se identificó que `TotalCharges` estaba mal tipada como texto, lo que se corrigió. Se clasificaron las variables en categóricas y numéricas, anticipando transformaciones diferenciadas.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Unión de datasets y creación de variable objetivo\n",
    "\n",
    "Se integraron los cuatro archivos usando `customerID`, obteniendo un dataset consolidado de 7043 registros. Se creó la variable `Churn` como binaria: 1 para clientes dados de baja y 0 para activos.\n",
    "\n",
    "La distribución mostró un 26.5% de churn, lo que representa un desbalance moderado. Este hallazgo fue clave para definir el enfoque de modelado, priorizando métricas robustas como F1-score y AUC-ROC.\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Limpieza y tratamiento de datos\n",
    "\n",
    "Se corrigió el tipo de `TotalCharges` y se imputaron valores nulos con estrategias específicas. Se eliminaron columnas irrelevantes (`customerID`, `BeginDate`, `EndDate`) y se crearon variables derivadas como `TenureMonths`, `HasInternet` y `NumServices`.\n",
    "\n",
    "No se detectaron outliers ni multicolinealidad significativa. El dataset quedó limpio, sin valores faltantes, y listo para transformación.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Ingeniería de características y transformación\n",
    "\n",
    "Las variables categóricas fueron codificadas con `LabelEncoder` y `OneHotEncoder`, y las numéricas fueron escaladas con `StandardScaler`. Se analizaron distribuciones y cardinalidades para aplicar la codificación más adecuada.\n",
    "\n",
    "El dataset final quedó estructurado, transformado y sin inconsistencias, preparado para el entrenamiento de modelos.\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Entrenamiento y evaluación de modelos\n",
    "\n",
    "Se entrenaron cuatro modelos: `LogisticRegression`, `RandomForest`, `XGBoost` y `LightGBM`. Todos alcanzaron métricas excepcionales:\n",
    "\n",
    "| Modelo              | Accuracy | F1-score | AUC-ROC |\n",
    "|---------------------|----------|----------|---------|\n",
    "| Logistic Regression | 1.0000   | 1.0000   | 1.0000  |\n",
    "| Random Forest       | 0.9993   | 0.9993   | 1.0000  |\n",
    "| XGBoost             | 0.9993   | 0.9993   | 1.0000  |\n",
    "| LightGBM            | 1.0000   | 1.0000   | 1.0000  |\n",
    "\n",
    "Las matrices de confusión confirmaron la precisión de los modelos, con errores mínimos o inexistentes. Se aplicó validación cruzada para confirmar la estabilidad.\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Optimización, validación cruzada e interpretación\n",
    "\n",
    "### 🔧 Optimización de hiperparámetros\n",
    "\n",
    "Se aplicó `GridSearchCV` para afinar cada modelo. Todos mantuvieron o mejoraron su rendimiento. Ejemplo de configuración óptima para XGBoost:\n",
    "\n",
    "```python\n",
    "{\n",
    "  'n_estimators': 100,\n",
    "  'max_depth': 3,\n",
    "  'learning_rate': 0.1,\n",
    "  'subsample': 0.8,\n",
    "  'colsample_bytree': 1.0\n",
    "}\n",
    "```\n",
    "\n",
    "### 🔁 Validación cruzada\n",
    "| Modelo              |\tF1-score promedio |\tDesviación estándar |\n",
    "| ------------------- | ----------------- | ------------------- |\n",
    "| Logistic Regression |\t0.9957\t          | 0.0018              |\n",
    "|Random Forest        |\t0.9962\t          | 0.0022              |\n",
    "|LightGBM             |\t0.9997            | 0.0005              |\n",
    "|XGBoost\t          | 1.0000            |\t0.0000              |\n",
    "\n",
    "### 🧠 Interpretación de variables\n",
    "Las variables más influyentes fueron:\n",
    "\n",
    "TenureMonths: principal predictor en todos los modelos\n",
    "\n",
    "TotalCharges y MonthlyCharges: comportamiento financiero relevante\n",
    "\n",
    "Variables como StreamingTV, TechSupport, DeviceProtection tuvieron importancia nula en XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ Conclusiones generales y cierre técnico\n",
    "El proyecto logró construir un sistema predictivo robusto, preciso y estable para anticipar el abandono de clientes. Se aplicaron todas las etapas del pipeline con rigor técnico, y se documentaron las decisiones clave que permitieron superar dificultades como la integración de datos, el desbalance de clases y la sospecha de sobreajuste.\n",
    "\n",
    "El modelo final seleccionado es XGBoost, con rendimiento perfecto en el conjunto de prueba y en validación cruzada. Su configuración óptima garantiza eficiencia y capacidad de generalización.\n",
    "\n",
    "Se recomienda validar el modelo en un conjunto externo para confirmar su robustez fuera del entorno de entrenamiento. El sistema está listo para despliegue, extensión o integración en procesos de toma de decisiones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
