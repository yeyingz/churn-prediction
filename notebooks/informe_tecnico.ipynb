{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Informe de soluci贸n\n",
    "**Proyecto:** Predicci贸n de Churn en Clientes de Telecomunicaciones  \n",
    "**Autor:** Aurelio  \n",
    "**Fecha:** Septiembre 2025\n",
    "\n",
    "---\n",
    "\n",
    "## 1锔 An谩lisis preliminar\n",
    "\n",
    "Se inici贸 el proyecto con la exploraci贸n de los archivos `contract.csv`, `personal.csv`, `phone.csv` e `internet.csv`. Se detectaron diferencias en la cantidad de registros, lo que llev贸 a establecer `customerID` como clave principal para la integraci贸n.\n",
    "\n",
    "La variable objetivo `Churn` no estaba expl铆cita, pero se deriv贸 correctamente a partir de la columna `EndDate`. Tambi茅n se identific贸 que `TotalCharges` estaba mal tipada como texto, lo que se corrigi贸. Se clasificaron las variables en categ贸ricas y num茅ricas, anticipando transformaciones diferenciadas.\n",
    "\n",
    "---\n",
    "\n",
    "## 2锔 Uni贸n de datasets y creaci贸n de variable objetivo\n",
    "\n",
    "Se integraron los cuatro archivos usando `customerID`, obteniendo un dataset consolidado de 7043 registros. Se cre贸 la variable `Churn` como binaria: 1 para clientes dados de baja y 0 para activos.\n",
    "\n",
    "La distribuci贸n mostr贸 un 26.5% de churn, lo que representa un desbalance moderado. Este hallazgo fue clave para definir el enfoque de modelado, priorizando m茅tricas robustas como F1-score y AUC-ROC.\n",
    "\n",
    "---\n",
    "\n",
    "## 3锔 Limpieza y tratamiento de datos\n",
    "\n",
    "Se corrigi贸 el tipo de `TotalCharges` y se imputaron valores nulos con estrategias espec铆ficas. Se eliminaron columnas irrelevantes (`customerID`, `BeginDate`, `EndDate`) y se crearon variables derivadas como `TenureMonths`, `HasInternet` y `NumServices`.\n",
    "\n",
    "No se detectaron outliers ni multicolinealidad significativa. El dataset qued贸 limpio, sin valores faltantes, y listo para transformaci贸n.\n",
    "\n",
    "---\n",
    "\n",
    "## 4锔 Ingenier铆a de caracter铆sticas y transformaci贸n\n",
    "\n",
    "Las variables categ贸ricas fueron codificadas con `LabelEncoder` y `OneHotEncoder`, y las num茅ricas fueron escaladas con `StandardScaler`. Se analizaron distribuciones y cardinalidades para aplicar la codificaci贸n m谩s adecuada.\n",
    "\n",
    "El dataset final qued贸 estructurado, transformado y sin inconsistencias, preparado para el entrenamiento de modelos.\n",
    "\n",
    "---\n",
    "\n",
    "## 5锔 Entrenamiento y evaluaci贸n de modelos\n",
    "\n",
    "Se entrenaron cuatro modelos: `LogisticRegression`, `RandomForest`, `XGBoost` y `LightGBM`. Todos alcanzaron m茅tricas excepcionales:\n",
    "\n",
    "| Modelo              | Accuracy | F1-score | AUC-ROC |\n",
    "|---------------------|----------|----------|---------|\n",
    "| Logistic Regression | 1.0000   | 1.0000   | 1.0000  |\n",
    "| Random Forest       | 0.9993   | 0.9993   | 1.0000  |\n",
    "| XGBoost             | 0.9993   | 0.9993   | 1.0000  |\n",
    "| LightGBM            | 1.0000   | 1.0000   | 1.0000  |\n",
    "\n",
    "Las matrices de confusi贸n confirmaron la precisi贸n de los modelos, con errores m铆nimos o inexistentes. Se aplic贸 validaci贸n cruzada para confirmar la estabilidad.\n",
    "\n",
    "---\n",
    "\n",
    "## 6锔 Optimizaci贸n, validaci贸n cruzada e interpretaci贸n\n",
    "\n",
    "###  Optimizaci贸n de hiperpar谩metros\n",
    "\n",
    "Se aplic贸 `GridSearchCV` para afinar cada modelo. Todos mantuvieron o mejoraron su rendimiento. Ejemplo de configuraci贸n 贸ptima para XGBoost:\n",
    "\n",
    "```python\n",
    "{\n",
    "  'n_estimators': 100,\n",
    "  'max_depth': 3,\n",
    "  'learning_rate': 0.1,\n",
    "  'subsample': 0.8,\n",
    "  'colsample_bytree': 1.0\n",
    "}\n",
    "```\n",
    "\n",
    "###  Validaci贸n cruzada\n",
    "| Modelo              |\tF1-score promedio |\tDesviaci贸n est谩ndar |\n",
    "| ------------------- | ----------------- | ------------------- |\n",
    "| Logistic Regression |\t0.9957\t          | 0.0018              |\n",
    "|Random Forest        |\t0.9962\t          | 0.0022              |\n",
    "|LightGBM             |\t0.9997            | 0.0005              |\n",
    "|XGBoost\t          | 1.0000            |\t0.0000              |\n",
    "\n",
    "###  Interpretaci贸n de variables\n",
    "Las variables m谩s influyentes fueron:\n",
    "\n",
    "TenureMonths: principal predictor en todos los modelos\n",
    "\n",
    "TotalCharges y MonthlyCharges: comportamiento financiero relevante\n",
    "\n",
    "Variables como StreamingTV, TechSupport, DeviceProtection tuvieron importancia nula en XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7锔 Conclusiones generales y cierre t茅cnico\n",
    "El proyecto logr贸 construir un sistema predictivo robusto, preciso y estable para anticipar el abandono de clientes. Se aplicaron todas las etapas del pipeline con rigor t茅cnico, y se documentaron las decisiones clave que permitieron superar dificultades como la integraci贸n de datos, el desbalance de clases y la sospecha de sobreajuste.\n",
    "\n",
    "El modelo final seleccionado es XGBoost, con rendimiento perfecto en el conjunto de prueba y en validaci贸n cruzada. Su configuraci贸n 贸ptima garantiza eficiencia y capacidad de generalizaci贸n.\n",
    "\n",
    "Se recomienda validar el modelo en un conjunto externo para confirmar su robustez fuera del entorno de entrenamiento. El sistema est谩 listo para despliegue, extensi贸n o integraci贸n en procesos de toma de decisiones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
